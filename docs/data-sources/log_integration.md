---
subcategory: "Log Integration"
---

# Data Source: mongodbatlas_log_integration

`mongodbatlas_log_integration` describes the configuration for a log integration identified by its unique ID. Log integrations are managed at the project level and allow you to continually export `mongod`, `mongos`, and audit logs to an AWS S3 bucket with 1-minute log export intervals.

To use this data source, the requesting Service Account or API Key must have the Organization Owner or Project Owner role.

## Example Usage
```terraform
resource "mongodbatlas_project" "project" {
  name   = var.atlas_project_name
  org_id = var.atlas_org_id
}

# Set up cloud provider access in Atlas using the created IAM role
resource "mongodbatlas_cloud_provider_access_setup" "setup_only" {
  project_id    = mongodbatlas_project.project.id
  provider_name = "AWS"
}

resource "mongodbatlas_cloud_provider_access_authorization" "auth_role" {
  project_id = mongodbatlas_project.project.id
  role_id    = mongodbatlas_cloud_provider_access_setup.setup_only.role_id

  aws {
    iam_assumed_role_arn = aws_iam_role.atlas_role.arn
  }
}

# Set up log integration with authorized IAM role
resource "mongodbatlas_log_integration" "example" {
  project_id  = mongodbatlas_project.project.id
  bucket_name = aws_s3_bucket.log_bucket.bucket
  iam_role_id = mongodbatlas_cloud_provider_access_authorization.auth_role.role_id
  prefix_path = "atlas-logs"
  type        = "S3_LOG_EXPORT"
  log_types   = ["MONGOD_AUDIT"]
}

data "mongodbatlas_log_integration" "example" {
  project_id     = mongodbatlas_log_integration.example.project_id
  integration_id = mongodbatlas_log_integration.example.integration_id
}

data "mongodbatlas_log_integrations" "example" {
  project_id = mongodbatlas_log_integration.example.project_id
}

output "log_integration_bucket_name" {
  value = data.mongodbatlas_log_integration.example.bucket_name
}

output "log_integrations_results" {
  value = data.mongodbatlas_log_integrations.example.results
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `integration_id` (String) Unique identifier of the log integration configuration.
- `project_id` (String) Unique 24-hexadecimal digit string that identifies your project.

### Read-Only

- `azure_container` (String) Azure Blob Storage container name for log files.
- `azure_prefix_path` (String) Blob path prefix for organizing log files within the container.
- `azure_service_principal_id` (String) Unique 24-character hexadecimal string that identifies the Azure Service Principal.
- `azure_storage_account_name` (String) Azure Storage Account name where logs will be stored.
- `bucket_name` (String) Human-readable label that identifies the S3 bucket name for storing log files.
- `gcs_bucket_name` (String) GCS bucket name for storing log files.
- `gcs_prefix_path` (String) GCS object path prefix for organizing log files.
- `gcs_role_id` (String) Unique 24-character hexadecimal string that identifies the GCP service account role.
- `iam_role_id` (String) Unique 24-hexadecimal digit string that identifies the AWS IAM role that MongoDB Cloud uses to access your S3 bucket.
- `kms_key` (String) AWS KMS key ID or ARN for server-side encryption (optional). If not provided, uses bucket default encryption settings.
- `log_types` (Set of String) Array of log types exported by this integration. The specific log types available and maximum number of items depend on the integration type. See the integration-specific schema for details.
- `otel_endpoint` (String) OpenTelemetry collector endpoint URL.
- `prefix_path` (String) S3 directory path prefix where the log files will be stored. MongoDB Cloud will add further sub-directories based on the log type.
- `region` (String) Datadog site/region for log ingestion. Valid values: US1, US3, US5, EU, AP1, AP2, US1_FED.
- `splunk_hec_url` (String) Splunk HTTP Event Collector (HEC) endpoint URL.
- `type` (String) Human-readable label that identifies the service to which you want to integrate with MongoDB Cloud. The value must match the log integration type.

For more information see: [MongoDB Atlas API - Log Integration](https://www.mongodb.com/docs/api/doc/atlas-admin-api-v2/group/endpoint-push-based-log-export) Documentation.

