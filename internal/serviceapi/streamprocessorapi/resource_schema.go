// Code generated by terraform-provider-mongodbatlas using `make generate-resource`. DO NOT EDIT.

package streamprocessorapi

import (
	"context"

	"github.com/hashicorp/terraform-plugin-framework-jsontypes/jsontypes"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/types"
)

func ResourceSchema(ctx context.Context) schema.Schema {
	return schema.Schema{
		Attributes: map[string]schema.Attribute{
			"group_id": schema.StringAttribute{
				Required:            true,
				MarkdownDescription: "Unique 24-hexadecimal digit string that identifies your project. Use the [/groups](#tag/Projects/operation/listProjects) endpoint to retrieve all projects to which the authenticated user has access.\n\n**NOTE**: Groups and projects are synonymous terms. Your group id is the same as your project id. For existing groups, your group/project id remains the same. The resource and corresponding endpoints use the term groups.",
			},
			"name": schema.StringAttribute{
				Optional:            true,
				MarkdownDescription: "Human-readable name of the stream processor.",
			},
			"options": schema.SingleNestedAttribute{
				Computed:            true,
				Optional:            true,
				MarkdownDescription: "Optional configuration for the stream processor.",
				Attributes: map[string]schema.Attribute{
					"dlq": schema.SingleNestedAttribute{
						Optional:            true,
						MarkdownDescription: "Dead letter queue for the stream processor.",
						Attributes: map[string]schema.Attribute{
							"coll": schema.StringAttribute{
								Optional:            true,
								MarkdownDescription: "Name of the collection to use for the DLQ.",
							},
							"connection_name": schema.StringAttribute{
								Optional:            true,
								MarkdownDescription: "Name of the connection to write DLQ messages to. Must be an Atlas connection.",
							},
							"db": schema.StringAttribute{
								Optional:            true,
								MarkdownDescription: "Name of the database to use for the DLQ.",
							},
						},
					},
					"resume_from_checkpoint": schema.BoolAttribute{
						Optional:            true,
						MarkdownDescription: "When true, the modified stream processor resumes from its last checkpoint.",
					},
				},
			},
			"pipeline": schema.ListAttribute{
				Optional:            true,
				MarkdownDescription: "Stream aggregation pipeline you want to apply to your streaming data.",
				ElementType:         jsontypes.NormalizedType{},
			},
			"state": schema.StringAttribute{
				Computed:            true,
				MarkdownDescription: "The state of the stream processor. Commonly occurring states are 'CREATED', 'STARTED', 'STOPPED' and 'FAILED'.",
			},
			"stats": schema.StringAttribute{
				Computed:            true,
				MarkdownDescription: "The stats associated with the stream processor.",
				CustomType:          jsontypes.NormalizedType{},
			},
			"tenant_name": schema.StringAttribute{
				Required:            true,
				MarkdownDescription: "Human-readable label that identifies the stream instance.",
			},
		},
	}
}

type TFModel struct {
	GroupId    types.String         `tfsdk:"group_id" autogen:"omitjson"`
	Name       types.String         `tfsdk:"name"`
	Options    types.Object         `tfsdk:"options"`
	Pipeline   types.List           `tfsdk:"pipeline"`
	State      types.String         `tfsdk:"state" autogen:"omitjson"`
	Stats      jsontypes.Normalized `tfsdk:"stats" autogen:"omitjson"`
	TenantName types.String         `tfsdk:"tenant_name" autogen:"omitjson"`
}
type TFOptionsModel struct {
	Dlq                  types.Object `tfsdk:"dlq"`
	ResumeFromCheckpoint types.Bool   `tfsdk:"resume_from_checkpoint"`
}
type TFOptionsDlqModel struct {
	Coll           types.String `tfsdk:"coll"`
	ConnectionName types.String `tfsdk:"connection_name"`
	Db             types.String `tfsdk:"db"`
}
